\chapter{Stellar Activity Modelling in Radial Velocity Time Series}
As discussed in Sect.~\ref{sect:activity}, there exists a multitude of physical
processes ongoing within the photospheres and chromospheres of active stars
that produce observable signatures with a variety of amplitudes and timescales
(see Table~\ref{table:activity}). The subsequent sections discuss a variety of
techniques that have been used to model and consequently mitigate the effects of
stellar activity in RV time series.

\section{An Overview of Techniques for Stellar Activity Mitigation}
\label{sect:methods}

\subsection{Stellar Activity as a Scalar Parameter}
Back when the first giant exoplanets where being discovered with RVs,
typically a treatment of stellar activity was not implemented. The reason being
that the measurement precisions of those datasets were insufficient to resolve the
temporal structure of RV activity for any but the most active stars. Many
observers however did report the root-mean-square (rms) of their RV residuals
following the removal of their best-fit planet model
\citep[e.g.][]{mayor95,butler96}. In
many cases it was revealed that the residual rms exceeded the characteristic RV
measurement uncertainty and thus alluded to the presence of additional
jitter signals that may or may not vary significantly with time. \\

In many of the following RV planet searches the apparent jitter was characterized
by an additive scalar jitter $s$. The free parameter $s$ was used to characterize the
level of RV jitter as it was added in quadrature to the RV measurement
uncertainties when evaluating the objective function during any analysis
equivalent or analogous to a $\chi^2$-minimization routine. The nature of this
method assumes a fixed level of dispersion due to jitter that is constant in time.
As such, the resulting
measurement of $s$ does little more than inform us of the jitter amplitude as
any temporal evolution of activity due to finite active region lifetimes or magnetic
cycles remained unresolved.

\subsection{Correlations with Activity Indicators} \label{sect:indicators}
Stellar RV observations are known to be affected by both planetary companions as
well as by stellar activity. Disentangling those signals in RV time series
therefore benefits significantly from ancillary time series that are sensitive
to stellar activity only \citep{boisse09}.
The classical implementation of de-correlation by
an activity indicator is to derive time series of one or many spectroscopic
activity indicators whose sampling is simultaneous with the RVs and then
fitting an often linear relation between those datasets (Fig.~\ref{fig:corr}) to
account for the temporal evolution of activity over the observational baseline.
The relation, when fitted simultaneously with planetary solutions, allows the RVs
to be de-correlated jointly with the measurement of the planetary parameters.
This technique has been shown to be reasonably effective when the stellar rotation period
\prot{} is well constrained, the planetary orbital period is distinct from
\prot{,} the amplitude of the planetary signal exceeds that of the activity signal
by $\gtrsim 30$\%, and the stellar rotation period is well sampled over multiple
cycles \citep{boisse11}. \\

\begin{figure}
  \centering
  \includegraphics[width=.6\textwidth]{figures/vspan_rv.png}
  \caption[Correlation between stellar RVs and the \vspan{} activity indicator.]
      {The correlation of the \vspan{} activity indicator with the RVs for the
    active Sun-like star HD 17051 from HARPS spectra. The solid line depicts the
    best-fit linear relation from least squares fitting. The fitted relation is
    used to de-correlate the RVs for the effects of stellar activity as probed by
    the \vspan{} time series. \citep[Image credit:][]{boisse11}.}
  \label{fig:corr}
\end{figure}

There exists a number of activity indicators that can be derived from the stellar
spectra. Their definitions and physical motivations are summarized below. \\

\emph{log R$'_{HK}$}:
the \caii{} H \& K resonance lines are excited by non-thermal heating 
and act as a sensitive indicator of chromospheric structure and particularly of
the presence of bright chromospheric plages. 
For optical spectra with access to the \caii{} H \& K lines
centered on 3968.47 \AA{} and 3933.66 \AA{,} the Mt. Wilson S-index is

\begin{equation}
  \text{S-index} \propto \frac{\Psi_H + \Psi_K}{\Psi_B + \Psi_V}
\end{equation}

\noindent where $\Psi_H$ and $\Psi_K$ represent the narrowband
($\sim 1.1$ \AA{} wide) fluxes in the cores of the H \& K lines of the \caii{}
doublet. The S-index is normalized by total flux in the $B$ and $V$ continuum bands
which are 20 \AA{} wide broad bands centered on 3900 and 4000 \AA{} respectively.
From the S-index, the \Rhk{} indicator is derived using a variety of formulations that are
all proportional to the S-index and attempt to isolate the chromospheric component of
$\Psi_H$ and $\Psi_K$ from the photospheric component using normalization factors
that are dependent on \teff{} and level of stellar activity \citep{lovis11}. The
\Rhk{} indicator has been well characterized as a sensitive probe of activity on
both Sun-like stars and M dwarfs
\citep[e.g.][]{wright04,lovis11,astudillodefru17b}. \\

$H\alpha$: 
similarly to the \Rhk{} index, H$\alpha$ photons ($\lambda = 6562.81$ \AA{)} are emitted by
hot plages and thus act as a tracer of stellar activity originating from the chromosphere.
H$\alpha$ may act as a more suitable spectroscopic activity indicator for cool M dwarfs
which lack significant flux in the \caii{} H \& K lines \citep{robertson14}.
In practical terms,  
similar spectral features tracing a star's chromospheric structure may alternatively be used
as activity indicators depending on the accessible wavelengths of the employed spectrograph
(e.g. \hei{,} \nai{,} etc). \\


\emph{CCF shape parameters}:
the cross-correlation function (CCF) of a stellar spectrum represents its average line profile
at typically a high S/N.
As was seen in Fig.~\ref{fig:starspot}, the presence of active regions distorts
the Gaussianity of the CCF thus alluding to the presence and nature of those active regions.
A number of shape parameters to the fitted CCF may be used to characterize stellar activity
using the same CCF from which the stellar RVs themselves are derived. However, these
spectroscopic diagnostics are only useful when they are robustly derived from high S/N
spectra of active stars where their effects on the CCF are clearly discernible \citep{desort07}.
Examples of three
shape parameters are visualized in Fig.~\ref{fig:ccf} and described below. \\

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/ccf.png}
  \caption[Illustrations of CCF shape parameters.]
          {Illustrations of measurements of the CCF width, asymmetry, and contrast via the full
            width half maximum (FWHM), bisector (BIS), and contrast shape parameters. The FWHM
            characterizes broadening of the CCF due to active regions at unique velocities on the
            stellar disk. The
            BIS characterizes the asymmetry of the line profile by computing the difference in
            average velocity in the upper and lower portions of the CCF (green circles in the
            middle panel). The contrast characterizes the depth of the CCF by taking the average
            of the CCF in the continuum (diamonds) and its difference with the CCF flux at the
            stellar velocity $V_0$.}
  \label{fig:ccf}
\end{figure}

\emph{FWHM}:
the full width half maximum (FWHM) of the CCF is commonly used as a measure of CCF's
width. As an active region transverses across the differentially
Doppler-shifted limbs of a rotating star,
its temperature contrast with the stellar photosphere adds additional
power to the CCF in the velocity direction opposite the occulted limb. This results in a
broadening of the CCF on one side of its mean velocity $V_0$. As illustrated in
the first panel in Fig.~\ref{fig:ccf},
the FWHM can be measured from the width of the CCF at a specified location. \\

\emph{BIS}:
recall that the broadening of the CCF due to a single active region is asymmetric about $V_0$.
A common shape parameter to characterize the resulting asymmetry is the bisector
\citep[BIS;][]{queloz01}.
Similar parameters have also been proposed as measures of CCF asymmetry such as the curvature of
the bisector line \citep{hatzes96}, the velocity span \citep{boisse11}, and the BIS inverse
slope \citep{queloz01}. Their definitions are closely related and rely on computing the weighted
velocity in the upper and lower portions of the CCF (see middle panel of Fig.~\ref{fig:ccf})
and calculating their difference. A symmetric line profile will therefore have a BIS$=0$ whereas
asymmetric profiles affected by active regions will be non-zero and whose exact value and units
will depend on the definition of the asymmetry parameter used. \\

\emph{Contrast}:
\citep{boisse09} noted that increasingly active stars, based on their fractional coverage by dark
star spots, tend to have shallower line profiles. This is the direct result of such stars featuring
more significant contributions to their average line profiles from cool and therefore dimmer regions.
This effect is often characterized by the CCF contrast which is equal to the difference between the
average baseline of the CCF in the continuum (located many standard deviations away from $V_0$ in
the CCF wings) and the flux at the stellar velocity $V_0$.


\subsection{Photometric Modelling: the \textbf{\emph{FF}}$'$ Method} \label{sect:ffp}
An alternative to using simultaneous spectroscopic activity indicators to temporally de-correlated
RV measurements for the effects of stellar activity is to use contemporaneous photometry.
\citep{aigrain12} present the $FF'$ formalism that uses photometry to model two distinct RV activity
components resulting from the active regions that give rise to photometric variability. In this way
the photometry is used to infer a quantity that is not directly observable (i.e. the fractional spot
coverage) from which various RV activity components are derived using the $FF'$ formalism
\citep{rajpaul15}. \\

\cite{aigrain12}
argue that in the limit of small active regions with non-complex configurations that the fractional
coverage of the stellar disk by active regions $F(t)$ is related to the photometric flux
$\Psi(t)$ via

\begin{equation}
  \Psi(t) = 1 - F(t).
  \label{eq:ffp}
\end{equation}

\noindent Eq.~\ref{eq:ffp} reads that the fractional spot coverage is just one minus the observed
stellar flux in normalized units such that the star's brightness equals unity in the absence of active
regions. The corresponding RV signals from a active regions giving rise to the photometric variations
are known
as the rotation effect $\Delta \text{RV}_{\text{rot}}$ and the convection blueshift effect
$\Delta \text{RV}_{\text{conv}}$. The former arises from active regions occulting the differentially
Doppler-shifted stellar limbs and thereby suppressing the flux of photons with a particular
Doppler-shift. Because the rotation effect affects the RVs in proportion to the spot coverage and
exhibits a sign change as the spot crosses from the blueshifted limb to the redshifted limb over a
single rotation cycle, the rotation effect is

\begin{equation}
  \Delta \text{RV}_{\text{rot}}(t) \propto F(t) \dot{F}(t),
\end{equation}

\noindent where the first time derivative of the fractional active region coverage is
$\dot{F}(t) = -\dot{\Psi}(t)$ from Eq.~\ref{eq:ffp}. As such, the rotation effect tends to dominate
on rapidly rotating stars wherein $\dot{F}(t)$ is large. Conversely, the convective blueshift effect
operates by active regions disrupting the homogeneity of the stellar disk on which convective
blueshift is ongoing everywhere. This disruption scales with the fractional spot coverage and
the angle between the spot normal and the line-of-sight which results in

\begin{equation}
  \Delta \text{RV}_{\text{conv}}(t) \propto F^2(t).
\end{equation}

\noindent The convective blueshift effect tends to dominate more slowly rotating spotted
stars such as the Sun \citep{haywood16}. \\

Fig.~\ref{fig:ffp} demonstrates both the rotation and
convective blueshift effects on the RVs and how they are related to the photometric detriment
incurred by a single spot over a portion of one stellar rotation cycle.

\begin{figure}
  \centering
  \includegraphics[width=0.8\hsize]{figures/ffp.png}
  \caption[Illustration of the $FF'$ method.]
      {The $FF'$ method for deriving the rotation and convective blueshift components
    of stellar RV activity from contemporaneous photometry. Here the photometric stellar flux
    is used to infer the fractional spot coverage $F(t)$. The rotation effect scales with
    $F(t) \dot{F}(t)$ and thus varies with half the period as does the convective blueshift
    effect that scales as $F^2(t)$. \citep[Image credit:][]{haywood15}.}
  \label{fig:ffp}
\end{figure}


\subsection{Pre-whitening}
This method aims at identifying strong periodicities in a RV time series by modelling
said periodic signals with sinusoids and removing them
until only residual Gaussian noise is remaining. This method is known as pre-whitening and
is based on analyzes of multi-periodic stellar oscillation modes. Pre-whitening operates
by performing a Fourier
transform of the data and removing sinusoidal functions from the raw data whose periods are
identified by the frequency analysis \citep{queloz09}. Pre-whitening however assumes that all
signals are long-lived and strictly periodic which is not always applicable to the stellar activity
signals that this method aims to mitigate.

\subsection{Deterministic Model Fitting}
RV time series exhibiting strong coherent signals at \prot{} or one of its low order
harmonics\footnote{For example the first harmonic of \prot{} can dominate for rapidly rotating
  spotted stars whose RV activity
  is dominated by the rotation effect (see Sect.~\ref{sect:ffp}).} may be well modelled by
a deterministic function in the form of a sinusoid at \prot{,} $P_{\text{rot}}/2$, $P_{\text{rot}}/3$,
etc \citep{boisse11}. In general, such models are incomplete because they neglect any temporal
evolution of active regions that vary in their sizes, temperatures, and spatial distributions
over adjacent rotation cycles \citep{giles17}. These nuances are not captured in 
deterministic sinusoidal models although this methodology may still be applicable for time series
with short observational baselines of stars with long-lived active region groups.

\subsection{Physical Models of Active Regions}
Another seemingly logical approach to modelling stellar activity is to parameterize a physical model
of active regions and sample those parameter posteriors jointly with planet models. This direct
spot modelling has been considered in \cite{giguere16} who fit a multi-spot model
to contemporaneous photometry and spectroscopic time series to determine the physical nature of
spots on the early K dwarf $\epsilon$ Eridani. This method however
suffers from issues resulting from attempting to sample such a large parameter space
such as the sheer computational expense and inherent degeneracies in spot parameters
\citep{giguere16}. Other prominent packages exist for generating forward models of observables
from physical spot models 
(\texttt{SOAP}; \citealt{boisse12}, \texttt{SOAP 2.0}; \citealt{dumusque14},
\texttt{StarSim}; \citealt{herrero16}) although I am unaware
of their usage for the purpose of directly modelling spots in RV time series.

\subsection{Line by line radial velocities}
Different spectral lines are known to be uniquely affected by stellar activity due to their
unique sensitivities to pressure, temperature, embedded magnetic field strength, and local fluid
velocities, all of which are influenced by stellar activity \citep{davis17,wise18}. These
effects from stellar activity on spectral line shapes are distinct from Doppler-induced
line shifts that are identical to all lines. \cite{dumusque18} investigated
the prospect of deriving stellar RVs line by line. The resulting RVs derived from
individual lines were shown to be
consistent with the archival RVs derived from the HARPS data reduction software.
The derivation of RVs in this way is postulated to mitigate anomalous RV signals
from stellar activity if spectral features that are minimally affected by activity
are utilized. Intelligent identification of lines that are minimally sensitive to
activity remains an active area of research. \\

\cite{davis17} also demonstrated the power of analyzing individual spectral lines
to identify the effect of stellar activity on measured RVs. Principal component analysis
was run on sets of idealized spectra from stars hosting either an equatorial spot,
an equatorial facula, or a planetary companion on a circular orbit. As shown in
Fig.~\ref{fig:pca}, the maximum variance contained in the first principal component
of the Doppler-shifted spectrum (i.e. with no activity) is maximized where the slope
of spectral features is greatest and is identical to all spectral features as they
are each equivalently affected by Doppler shifts. Lines in the remaining synthetic
spectra that are affected by either a spot or facula are not identically affected due
to the differential sensitivity of various lines to their physical environment
that in turn is influenced by the presence of active regions. Fig.~\ref{fig:pca}
reveals examples of strongly varying lines from Ti \footnotesize I \normalsize and Ni
\footnotesize I \normalsize at 5009.5 \AA{} and 5010.8 \AA{} respectively.
\cite{davis17} also quantify the wealth of information contained in the spectra
as a function of S/N and spectral resolution and argue for the need to obtain
high resolution spectra to finely resolve line profiles and exploit their inherent
activity information content.

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/pca.png}
  \caption[Principal component analysis of idealized spectra containing either spots, faculae, or planets.]
          {The values of the first principal component for three spectra of a star with either an equatorial
            spot, an equatorial facula, or a circular keplerian orbit. The maximum variance (with either sign)
            in the Doppler-shifted spectrum is dominated by regions with the greatest slope and is the same
            for all spectral features. Variance in the active spectra and not equal within each line as not all
            lines respond identically to in the presence of active regions. \citep[Image credit:][]{davis17}}
  \label{fig:pca}
\end{figure}


\section{Gaussian Process Regression for Semi-Parametric Activity Modelling} \label{sect:gp}
Many of the shortcomings of the activity mitigation techniques discussed in the
previous sections are based on their incompleteness and their inability to
self-consistently characterize model uncertainties. For example, correlations with
activity-sensitive time series are often incomplete because the chosen indicator
is not sensitive to also activity sources present in the RVs and often result in
large RV residuals after de-correlation. Similarly, deterministic activity models
lack sensitivity to stochastic changes in activity levels due to the evolution
of active regions between adjacent rotation cycles or over
significant subsets of long-term magnetic cycles. \\

Gaussian process regression models represent one such tool that aims to overcome
many of these shortcomings by jointly modelling planets and activity in a self-consistent
manner. This technique, originally pioneered on active Sun-like stars
\citep[e.g.][]{haywood14,grunblatt15,faria16,lopezmorales16},
has been shown to reconcile disparate solutions
between observations from multiple spectrographs \citep{rajpaul17,cloutier19a},
to reconcile RV solutions for planetary systems whose favoured models are
ambiguous \citep{rajpaul17,cloutier19a}, and to disentangle neighbouring periodic
signals from planets, stellar rotation, and/or from window functions
\citep{rajpaul16,cloutier17b}.
In the following sections I will give an overview
of what Gaussian processes are and how I implement their formalism in the context
of modelling stellar activity in RV time series. \\

Before proceeding it is important
to note that Gaussian process regressionmodels of activity are not the be all end all
when it comes to activity modelling in RV time series. As will be argued throughout this
thesis though, Gaussian process activity
modelling does provide a tractable framework with many desirable properties for deriving
models of stochastic activity signals in RVs.

\subsection{The one-dimensional Gaussian distribution}
A Gaussian process (GP) is defined as \emph{a collection of random variables, any
finite subset of which has a joint Gaussian distribution}. In other words,
any random process\footnote{A random process is any collection of random
  variables indexed by an independent variable such as time.} for which all
finite subsets have a multivariate Gaussian distribution, is a Gaussian process
\citep{rasmussen05}. The following discussion is intended to help the reader
develop an intuition of what a Gaussian process is. Much of the information
provided and the pedogical approach taken throughout was acquired from a video lecture
by Prof. David MacKay\footnote{\url{https://www.youtube.com/watch?v=NegVuuHwa8Q}}. \\

In order to develop a visual intuition of the definition of a Gaussian process,
let us a first consider a Gaussian random variable in one dimension. 
So, imagine some random
process that draws a single value of a random variable $X$ for each realization of
an experiment. As an astronomer with a life
outside of astronomy, and furthermore as an astronomer who spends many of his
off-work hours being pelted with %170 gram
disks of vulcanized rubber, my favourite
Gaussian random variable has to be the `goals against average' statistic:

\begin{equation}
  X = GAA \equiv \frac{\text{total number of goals against}}{\text{total number of games played}}.
\end{equation}

\noindent As a Gaussian random variable, the results of repeated experiments (i.e.
repeated draws from the empirical $GAA$ distribution for various goaltenders) can
be expressed by the Gaussian probability density function (PDF) of the form

\begin{equation}
  \mathcal{N}(X|\mu,\sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}} \exp{\left(
    -\frac{(X-\mu)^2}{2\sigma^2} \right)},
  \label{eq:gauss}
\end{equation}

\noindent that is parameterized by $\mu=\text{mean}(X)$ and $\sigma^2=\text{var}(X)$;
the mean and variance of $X$. As shown in Fig.~\ref{fig:gaa1d}, the empirical
distribution of the $GAA$ for goaltenders in
the National Hockey League (NHL) over the past five seasons closely follows a
Gaussian distribution with a mean of 2.64 and a standard deviation of 0.40 goals
against per game. Hence, my favourite Gaussian random variable. \\

\begin{figure}
  \centering
  \includegraphics[width=.8\textwidth]{figures/GAA1D.png}
  \caption[Gaussian random variable in one dimension.]
      {The distribution of $GAA$ for NHL goaltenders over the past five
    seasons as an example of a Gaussian random variable. The solid line depicts
    the Gaussian probability density function with mean and standard
    deviation 2.64 and 0.40 goals against per game.}
  \label{fig:gaa1d}
\end{figure}

Before a new season begins, we can write down a prior distribution on the $GAA$
based on the prior knowledge we have obtained from previous NHL seasons; i.e.
$\mathcal{N}(GAA|2.64,0.16)$. This distribution has a unique expectation value and
variance describing what we expect any given goaltender's $GAA$ to be in an
up-coming season and, as crucially, how precisely that value is constrained.

\subsection{The two-dimensional Gaussian distribution}
Of course we can introduce a second Gaussian random variable and extend the 
concept of the one-dimensional Gaussian distribution to two dimensions. This is done
by recasting the expression for the Gaussian PDF in $k>1$
dimensions where $k=2$ in this scenario. Rewriting Eq.~\ref{eq:gauss} in $k$
dimensions is achieved by replacing the scalar mean and variance with a mean
$k$-vector $\boldsymbol{\mu}$ and a $k \times k$ covariance matrix $\mathbf{K}$
respectively. The updated expression for the so-called multivariate Gaussian
distribution in $k$ dimensions is

\begin{equation}
  \mathcal{N}(\mathbf{X}|\boldsymbol{\mu},\mathbf{K}) = \frac{1}{\sqrt{(2\pi)^k
      |\mathbf{K}|}} \exp{\left( -\frac{1}{2} (\mathbf{X} -
    \boldsymbol{\mu})^{\text{T}} \mathbf{K}^{-1} (\mathbf{X}-\boldsymbol{\mu})
    \right)}.
  \label{eq:gauss2d}
\end{equation}

\noindent The $k$-vector $\boldsymbol{\mu}$ represents the mean value of each
random variable in $\mathbf{X}=(X_1,\dots,X_k)^{\text{T}}$.
The elements of the covariance matrix
$\mathbf{K}$ represent the covariances between each pair of random variables.
The diagonal elements of $\mathbf{K}$ therefore represent the covariance of each
random variable with itself, or equivalently the variance of that random variable.
The covariance between two random variables $X_1$ and $X_2$ can be computed explicitly
in terms of their expectation values E[$X_1$] and E[$X_2$] via

\begin{align}
  \text{cov}(X_1X_2) &= \text{E}[(X_1-\text{E}[X_1]) - (X_2-\text{E}[X_2])] \\
  &= \text{E}[X_1X_2] - \text{E}[X_1]\text{E}[X_2].
  \label{eq:coveq}
\end{align}

\noindent Note that the expectation value of a Gaussian random variable is simply
its mean. \\

\subsubsection{Uncorrelated variables}
Consider the special case of when the two Gaussian random variables under
consideration $X_1$ and $X_2$ are uncorrelated; i.e. cov$(X_1X_2)=0$. A quick
example of this is to let $X_1=GAA$ and sample $X_2$ from an independent Gaussian
distribution with zero mean and unit variance.
The nature of sampling $X_2$ in this way ensures
that $X_1$ and $X_2$ are indeed uncorrelated. The corresponding covariance matrix

\begin{equation}
  \mathbf{K}(GAA,X_2) =
  \begin{bmatrix}
    0.15 & 0.00 \\
    0.00 & 0.98
  \end{bmatrix}
  \label{eq:Kuncorr}
\end{equation}

\noindent is calculated using Eq.~\ref{eq:coveq}, is diagonal, and confirms that
$X_1$ and $X_2$ are uncorrelated as the off-diagonal elements of $\mathbf{K}$ are zero.
This fact can also be visually discerned in the joint $X_1X_2$ distribution in
Fig.~\ref{fig:uncorr2d}. Because the variables $X_1$ and $X_2$ are uncorrelated in this,
example the measurement of a value of $X_1$ does nothing to inform us of its
corresponding $X_2$ value. That is that the prior distribution
$\mathcal{N}(\mathbf{X}|\boldsymbol{\mu},\mathbf{K})$ is uninformative with regards to
$X_2$ in a sample for which the corresponding value of $X_1$ is known. \\

\begin{figure}
  \centering
  \includegraphics[width=.9\textwidth]{figures/uncorr_2d.png}
  \caption[Uncorrelated Gaussian random variables in two dimensions.]
      {The marginalized and joint distributions of the Gaussian random
        variables $GAA$ and draws from the standard normal distribution (i.e. $\mathcal{N}(0,1)$).
        The solid
    lines overlaid on their joint distribution represent the 1, 2, and 3$\sigma$
    contours. The covariance matrix (Eq.~\ref{eq:Kuncorr}) has off-diagonal
    elements equal to zero indicating that the two variables are uncorrelated;
    a property that is largely discernible from the lack of correlation in their joint
    distribution.}
  \label{fig:uncorr2d}
\end{figure}

\subsubsection{Correlated variables}
But what if next we consider an alternate Gaussian random variable. Namely
$X_2 = SV$\% where

\begin{equation}
  SV\% \equiv \frac{\text{total number of saves made}}{\text{total number of shots faced}}
\end{equation}

\noindent is a measure of a goaltender's save percentage. In this scenario one
might expect the variables $GAA$ and $SV$\% to have some degree of correlation
as a ``good'' goaltender who boasts a low $GAA$ probably does so because of their
high $SV$\%. Indeed the covariance matrix of the $GAA$ and $SV$\% for NHL
goaltenders over the past five seasons is

\begin{equation}
  \mathbf{K}(GAA,SV\%) =
  \begin{bmatrix}
    0.1496 & -0.0037 \\
    -0.0037 & 0.0001
  \end{bmatrix}
  \label{eq:Kcorr}
\end{equation}

\noindent and has non-zero off-diagonal elements. Furthermore, the off-diagonal
elements are negative which is indicative of the anti-correlation between the
$GAA$ and the $SV$\% that was just postulated. This strong correlation
is easily visualized in their joint distribution in Fig.~\ref{fig:corr2d}. \\


% see /Users/ryancloutier/Talks/CEHWcolloquium/GP_examples.ipynb
\begin{figure}
  \centering
  \includegraphics[width=0.9\hsize]{figures/corr_2D_HARTpost_logo_bkgd.png}%
  \hspace{-0.9\hsize}%
  \begin{ocg}{fig:logosoff}{fig:logosoff}{0}%
  \end{ocg}%
  \begin{ocg}{fig:logoson}{fig:logoson}{1}%
    \includegraphics[width=0.9\hsize]{figures/corr_2D_HARTpost_logo_logos.png}%
  \end{ocg}
  \hspace{-0.9\hsize}%
  \caption[Correlated Gaussian random variables in two dimensions.]
      {The marginalized and joint distributions of the Gaussian random
    variables $GAA$ and $SV$\%.
    The covariance matrix (Eq.~\ref{eq:Kcorr}) has negative off-diagonal
    elements describing the degree of anti-correlation between the two
    variables; a property that is largely discernible from their joint
    distribution as high values of the $SV$\% tend to correspond to a lower
    $GAA$. The correlation can be used to inform the value of one variable given a
    measurement of the other. This is demonstrated as the measured $GAA$ 
    for the Toronto Maple Leafs' goaltender 
    \ToggleLayer{fig:logoson,fig:logosoff}{\protect\cdbox{(vertical dashed line)}}
    provides some
    additional information on the corresponding $SV$\% whose posterior given the
    measured $GAA$ is more tightly constrained than the $SV$\% distribution for
    the entire NHL.}
  \label{fig:corr2d}
\end{figure}

The fact that the two variables are
correlated implies that knowledge of one variable provides some additional constraining
power on the value of the second. This demonstrated in Fig.~\ref{fig:corr2d}
wherein we measure the value of the $GAA$ for the Toronto Maple Leafs' goaltender
Freddie Andersen
to be 2.57 goals per game. Not bad. Not great, but not bad. By measuring
this value we can establish a posterior distribution on Freddie's corresponding
$SV$\% given his $GAA$: $p(SV\%|GAA=2.57)$. Because the variables are dependent
on each other according to Eq.~\ref{eq:Kcorr}, this posterior distribution is
narrower (i.e. more precise) than the full $SV$\% distribution. Indeed this is
evidenced in the lower right panel of Fig.~\ref{fig:corr2d} that compares the
two $SV$\% distributions and reveals that the dispersion in $p(SV\%|GAA=2.57)$
has approximately half of the dispersion as does the full $SV$\% distribution. The degree
of improvement in the predictive distribution of $X_2$ given $X_1$ is dependent
on how strongly correlated the two variables are. \\

\subsection{The $k$-dimensional Gaussian distribution}
So far we have considered a pair of correlated Gaussian random variables whose
PDF is given by Eq.~\ref{eq:gauss2d} for $k=2$. Next we want to extend the multivariate
Gaussian distribution to arbitrarily large $k$ and visualize that distribution which
cannot be done with the conventional contour-based visualization
(Figs.~\ref{fig:uncorr2d} \&~\ref{fig:corr2d}) beyond two dimensions. To resolve this
restriction we now adopt an alternative visualization of a multivariate Gaussian
distribution that I refer to as its \emph{linear representation}. \\

This new visualization is
depicted in Fig.~\ref{fig:linrep} for the $GAA$ and the $SV$\% alongside the conventional
representation. Specifically, Fig.~\ref{fig:linrep}
depicts a finite number of samples from the two-dimensional Gaussian distribution shown
in Fig.~\ref{fig:corr2d}. Each identically coloured line in the
linear representation depicts the values of the scaled $GAA$ and the $SV$\%\footnote{Note
  that the $GAA$ and $SV$\% are scaled to a common unit such that they span roughly
  the same region of the y-axis in the Fig.~\ref{fig:linrep} linear representation.
  The scaling is also such that the correlation between the scaled $GAA$ and $SV$\% is
  now positive (i.e. not anti-correlated).} for a single
sample from their joint distribution. Furthermore, the correlation between the two variables,
that we now insist be a positive correlation, is qualitatively apparent as a low value
of the scaled $GAA$ often corresponds to a low value of the scaled $SV$\%. If the two
variables were weakly correlated then we would expect more crossing of curves in the
linear representation then is seen in Fig.~\ref{fig:linrep}. What's more is that the
distribution of values in the vertical direction represent samples from each variable's
one-dimensional marginalized distribution such that the samples are indicative of the
variable's mean and variance. \\

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/linearrep_v1.png}
  \caption[Linear representation of Gaussian random variables in two dimensions.]
          {Visual comparison of samples from the two-dimensional Gaussian distribution
            depicted in the conventional way (\emph{left panel}) and in the new linear
            representation (\emph{right panel}).
            The $GAA$ and $SV$\% variables are scaled to a common unit with a
            positive correlation and offset for clarity.}
  \label{fig:linrep}
\end{figure}


The benefit of adopting the new linear representation is that it can be extended to
arbitrarily large dimensions. Fig.~\ref{fig:linrepv2} depicts the linear representation
of a $k=5$ dimensional space that includes three new Gaussian random variables that
are defined to be positively correlated with the scaled $GAA$ and $SV$\%. The left panel
in Fig.~\ref{fig:linrepv2} depicts samples from the five-dimensional Gaussian distribution
as well as each variable's mean and $1\sigma$ dispersion. The right panel of
Fig.~\ref{fig:linrepv2} illustrates the effect of how the measurement of one of the variables
informs the posteriors of the other variables as a result of their correlation. That is
that when the third variable in Fig.~\ref{fig:linrepv2} is measured and its uncertainty
goes to zero, the posterior distributions on the remaining variables are narrowed. As
more and more variables are measured, constraints on the unmeasured variables would
similarly increase in a way that is quantified by the correlations between the
measured and unmeasured variables.
The notion that the value of an unseen variable can be informed by the measurement
of another, if those variables are correlated, has major implications for
predictive models as we shall see in Sect.~\ref{sect:regression}. \\

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/linearrep_v2.png}
  \caption[Linear representation of Gaussian random variables in five dimensions.]
          {The linear representation of samples from a five-dimensional Gaussian
            distribution with each sample depicted with a particular colour in each
            panel. The mean and $1\sigma$ dispersion of each variable is depicted
            by the offset black markers and error bars. The \emph{right panel} illustrates
            how the measurement of the third variable constrains the values of the
            remaining variables due to their correlations.}
  \label{fig:linrepv2}
\end{figure}


\subsection{Gaussian process regression modelling} \label{sect:regression}
Upon inspection of Fig.~\ref{fig:linrepv2}, one might imagine changing the ``variables''
axis to an independent variable such as time and the ``scaled values'' axis to an
observable such as stellar RVs. In this way we would be looking at a time series and
particularly at the correlation between adjacent measurements. 
Because RV signals arising from active stars are temporally
correlated as active regions rotate in and out of the view of the observer, it is clear that
modelling the correlation between adjacent RV observations could be used to inform
our understanding of that signal in a way that is independent of attempting to
model the physical nature of the signal. \\

Indeed one-dimensional GP regression models are a convenient way to model
correlations between observations in a semi-parametric way. In particular, GPs provide a
flexible framework to perform Bayesian inference on functions. Their flexibility stems from
their semi-parametric nature which makes them well-suited to modelling stochastic processes
like stellar activity that lack a deterministic functional form. GP regression works to model
the covariance between data points simultaneously with deterministic components such as planets
on keplerian orbits. Given a parameterization of the data covariance structure, the GP is
by definition a multivariate Gaussian distribution with a well-defined mean function and
variance that represent our model of the correlated observables and its uncertainty
\citep{rasmussen05}. \\

\subsubsection{Covariance kernel functions}
Modelling of temporally correlated stellar activity with a GP regression model first requires
a parameterization of the data covariance. This parameterization of an analytical
covariance kernel through a small set of hyperparameters\footnote{``Small''
  relative to the number of RV measurements.} is why GP regression models are often referred to
as semi-parametric. The covariance matrix of the GP is written in terms of the covariance kernel
function $k(t,t')$ as

\begin{equation}
  \mathbf{K}_{ij} = k(t_i,t_j) + \delta_{ij} \sqrt{\sigma_{\text{RV}}^2(t_i) + s^2} 
\label{eq:Kmat}
\end{equation}

\noindent where the indices $i,j$ run up to the number of RV measurements (i.e. $i,j=1,\dots,$\nrv{)}.
Because of the Dirac delta function $\delta_{ij}$ in Eq.~\ref{eq:Kmat}, the 
diagonal of the covariance matrix $\mathbf{K}$ includes direct contributions from the
RV measurement uncertainties \sigRV{} plus an additive scalar jitter $s$ designed to absorb excess
white noise from systematics and/or from other temporally independent noise sources. \\

A number of covariance kernels have been proposed for the treatment of stellar RV activity
and are summarized below \citep{grunblatt15}. Their corresponding covariance
matrices are also shown in Fig.~\ref{fig:matrices}. \\

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/gpmatrices.png}
  \caption[Example of covariance matrices.]
          {Examples of covariance matrices with a squared exponential covariance kernel (\emph{left}),
            a periodic covariance kernel (\emph{middle}), and a quasi-periodic covariance kernel (\emph{right}).
            In the latter example the exponential timescale exceeds the periodic timescale such that the
            nearly periodic nature of the covariance is still discernible for points closely separated
          in time (i.e. near the matrix diagonal).}
          \label{fig:matrices}
\end{figure}

\emph{Squared exponential}: 

\begin{equation}
  k_{\text{SE}}(t_i,t_j) = a^2 \exp{\left[ -\frac{(t_i-t_j)^2}{2\lambda^2} \right]},
\end{equation}

\noindent has two hyperparameters $\boldsymbol{\Theta}=\{a, \lambda \}$.
Namely, the covariance amplitude $a$ in units of the observable,
and an exponential timescale $\lambda$ describing how much time is required for measurements to
effectively forget previous values. With this covariance kernel, measurements made closely in time
are more highly correlated than well separated measurements and the degree of correlation for a
given time separation will be larger for smaller $\lambda$. \\

\emph{Periodic}:

\begin{equation}
  k_{\text{P}}(t_i,t_j) = a^2 \exp{\left[ -\Gamma \sin^2{\left( \frac{\pi |t_i-t_j|}{P} \right)} \right]},
\end{equation}

\noindent has three hyperparameters  $\boldsymbol{\Theta}=\{a, \Gamma, P \}$
that includes the familiar covariance amplitude $a$. The periodic kernel
also contains a coherence parameter $\Gamma$ and a periodic timescale $P$ within the sinusoidal term.
With this covariance kernel, measurements that are separated by an integer number of $P$ will be highly
correlated. \\

\emph{Quasi-periodic}:

\begin{equation}
  k_{\text{QP}}(t_i,t_j) = a^2 \exp{\left[ -\frac{(t_i-t_j)^2}{2\lambda^2} -\Gamma
      \sin^2{\left( \frac{\pi |t_i-t_j|}{P} \right)} \right]},
  \label{eq:GpQp}
\end{equation}

\noindent is the product of the squared exponential and periodic covariance kernels and therefore
contains all four unique hyperparameters among the two kernels
$\boldsymbol{\Theta}=\{a, \lambda, \Gamma, P \}$. \\

Stellar activity on M dwarfs
is dominated by active regions \citep{lindegren03}\footnote{And sometimes flares but those
  occur on short timescales such that they rarely affect low cadence RV observations for almost
  all but the most active flare stars.} and the resulting RV signals evolve in a manner that
is easy to understand qualitatively. Namely, we can expect a periodic component to the
RV correlations because active regions rotate in and out of view at the stellar rotation period
although the periodicity of the correlations need not be at \prot{} and may instead appear
at a low order harmonic of \prot{} such as in the case of rapidly rotating spotted stars 
(see Sect.~\ref{sect:ffp}). But in addition to these periodic variations we can also expect activity
arising from active regions to not be strictly periodic because of active region evolution through
which their sizes, temperatures, and spatial distributions will vary. Thus we
have a physical justification for the adaption of a
quasi-periodic covariance kernel as it includes the first-order periodic structure of the activity
signal as well as the squared exponential term
whose timescale can be thought of as characterizing the active region lifetimes. \\

The optimization of the quasi-periodic covariance kernel over competing kernel functions
was demonstrated by \cite{grunblatt15} on the active Sun-like star Kepler-78. However, it
should be noted that due to the semi-parametric nature of GP regression models, the exact
choice of kernel and/or the exact values of its hyperparameters often do not matter as
much as one might think. Fig.~\ref{fig:exactgp} illustrates this notion by modelling a
set of synthetic data points with each of the three covariance functions defined above.
The synthetic data are generated by a sinusoidal function plus a decreasing linear trend. 
Each GP does a qualitatively similar job at modelling the data and with comparable $1\sigma$
uncertainties.  \\

Also depicted in Fig.~\ref{fig:exactgp} is the effect of varying the hyperparameters of
a quasi-periodic GP regression model to the same synthetic data. The first curve depicts
the resulting GP model using the approximate optimized hyperparameters with a periodic
timescale approximately equal to the injected timescale of 50 (arbitrary units). The second
GP model has the same periodic timescale but whose exponential timescale is greater by nearly
three orders of magnitude relative to the first curve.
Despite this, the resulting mean GP appears to continue to be a good
fit to the data. The final GP model reverts back to the optimized exponential timescale but
decreases the periodic timescale from 50 to 20. The effect of a shorter periodic timescale
is only apparent in the regions between data points as the resulting GP again appears to do
a qualitatively similar job at modelling the data despite having widely varying hyperparameters.
This exercise was intended to demonstrate that for some datasets, the exact form of the covariance
kernel or the exact values of the hyperparameters does not always have a drastic effect on the
model prediction at the epochs of observations. Although it is clear from Fig.~\ref{fig:exactgp}
that predictions from each unique GP can vary widely at times far from the epochs of observation.

\begin{figure}
  \centering
  \includegraphics[width=0.8\hsize]{figures/gpkernels.png}
  \includegraphics[width=0.8\hsize]{figures/gpkernelvalues.png}
  \caption[Behaviour of GPs with different covariance kernels and hyperparameters.]
          {\emph{Top panel}: the behaviour of three GP models with different covariance
            kernel functions on a synthetic dataset. \emph{Bottom panel}: the behaviour of three
            quasi-periodic GP models with varying hyperparameters. Each GP, regardless of
            covariance kernel or hyperparameters, exhibits
            a qualitatively similar behaviour in the vicinity of the data points.}
          \label{fig:exactgp}
\end{figure}


\subsubsection{Hyperparameter estimation}
Determination of the GP hyperparameters $\boldsymbol{\Theta}$ for a given covariance kernel is
done by first specifying a mean model $\boldsymbol{\mu}$ which itself is parameterized by
a set of model parameters $\boldsymbol{\theta}$. In the case of modelling RVs, the mean model
might represent our planet model whose keplerian orbital parameters are what we are interested
in measuring with the GP being used to model the correlated RV residuals arising from stellar
activity. The residual vector is written as $\mathbf{r} = \mathbf{y} - \boldsymbol{\mu}$
where $\mathbf{y}$ is the vector of \nrv{} RV measurements. 
To estimate all model parameters, including the GP hyperparameters and mean model
parameters (i.e. $\boldsymbol{\Psi} = \boldsymbol{\Theta} \cup \boldsymbol{\theta}$),
we sample their joint posterior according to Bayes theorem

\begin{equation}
  p(\boldsymbol{\Psi}|\mathbf{y}) \propto \mathcal{L}(\mathbf{y}|\boldsymbol{\Psi}) \cdot
  \Pi(\boldsymbol{\Psi})
  \label{eq:bayess}
\end{equation}

\noindent where

\begin{equation}
  \mathcal{L}(\mathbf{y}|\boldsymbol{\Psi}) =
  -\frac{1}{2} \left( \mathbf{r}^{\text{T}} \mathbf{K}^{-1} \mathbf{r} +
  \ln{\text{det}\mathbf{K}} + N_{\text{RV}} \ln{2\pi} \right)
  \label{eq:lnlikeGP}
\end{equation}

\noindent is the logarithmic likelihood function given the set of model parameters
$\boldsymbol{\Psi}$ and $\Pi(\boldsymbol{\Psi})$ represents our prior on
the model parameters. When estimating the GP hyperparameters in practice we
often sample the logarithmic hyperparameters and adopt broad log uniform priors
unless otherwise stated. Note that in Eq.~\ref{eq:bayess}
we have neglected the normalization factor that is not required
for the purpose of parameter estimation. \\

Sampling of the $\boldsymbol{\Psi}$ posteriors is done using MCMC. In this way, our
uncertainties in the keplerian model parameters $\boldsymbol{\theta}$
are marginalized over our uncertainties in
the GP hyperparameters $\boldsymbol{\Theta}$. The exact strategies and details of
our MCMC implementation are discussed in subsequent chapters
as necessary. After sampling the $\boldsymbol{\Psi}$ posteriors, the values of the
hyperparameters are obtained from the maximum a-posteriori point estimates of those
posteriors that in turn are used to define our GP activity model.

\subsubsection{Model inference}
From the set of maximum a-posteriori hyperparameters $\boldsymbol{\Theta}$,
we define a unique GP prior distribution. From this distribution we can sample
functions or construct a predictive distribution
conditioned on the data $\mathbf{y}(\mathbf{t})$ and evaluated at some unseen
epochs $\mathbf{t}^*$. Function prediction from such a predictive distribution is
historically known as kriging. The mean function and standard deviation of the
predictive distribution are

\begin{equation}
  \boldsymbol{\mu}(\mathbf{t}^*) = \mathbf{K}(\mathbf{t}^*,\mathbf{t}) \cdot
  \mathbf{K}(\mathbf{t},\mathbf{t})^{-1} \cdot \mathbf{y}(\mathbf{t}),
  \label{eq:gpmu}
\end{equation}

\noindent and

\begin{equation}
  \boldsymbol{\sigma}(\mathbf{t}) = \mathbf{K}(\mathbf{t}^*,\mathbf{t}^*) -
  \mathbf{K}(\mathbf{t}^*,\mathbf{t}) \cdot \mathbf{K}(\mathbf{t},\mathbf{t})^{-1}
  \cdot \mathbf{K}(\mathbf{t}^*,\mathbf{t})^{\text{T}}.
  \label{eq:gpsig}
\end{equation}

Figs.~\ref{fig:gpsamples} and~\ref{fig:gpsamplespred} depict samples from a
quasi-periodic GP prior and predictive distributions respectively. The latter is
conditioned on an set of ten synthetic data points and whose mean function and
standard deviation are computed using Eqs.~\ref{eq:gpmu} and~\ref{eq:gpsig}. When
modelling RV activity with a GP whose hyperparameters $\boldsymbol{\Theta}$ have
been derived from MCMC, we take the ``best-fit'' of that multivariate Gaussian, namely
its mean function, to be our activity model similarly to how maximum a-posteriori
point estimates of keplerian orbital parameters are used to compute a ``best-fit''
planet model. \\

\begin{figure}
  \centering
  \animategraphics[width=\textwidth,controls,loop]{5}{figures/GPsample_}{0}{49}
  \caption[Samples from a quasi-periodic Gaussian process prior distribution.]
          {??Continuous samples from a quasi-periodic Gaussian process prior distribution.
            A discontinuity in the sampling occurs after 50 frames. This animation was
            generated using code written by Jo\~ao
            Faria (\url{https://joaofaria.space/blog/continuous-samples}).}
  \label{fig:gpsamples}
\end{figure}

\begin{figure}
  \centering
  \animategraphics[width=\textwidth,controls,loop]{5}{figures/GPsample_pred_}{0}{49}
  \caption[Samples from a quasi-periodic Gaussian process predictive distribution.]
          {??Independent samples from a quasi-periodic Gaussian process predictive distribution
            conditioned on ten synthetic data points. The mean function and
            $1\sigma$ standard deviation are depicted as the dashed black curve and surrounding
          shaded region respectively.}
  \label{fig:gpsamplespred}
\end{figure}


\subsection{Demonstrating the effectiveness of a GP activity model: a toy model}
Here I will provide a quick demonstration of the effectiveness of using a semi-parametric GP
to model the temporally correlated physical process of stellar RV activity. The forthcoming
experiment is not intended to be representative of the performance of GP activity modelling
in general but it is useful to demonstrate how a non-physical model in the form of a GP can
aid in the accurate modelling of RV planets and activity. \\

Firstly, I construct
a set of synthetic RVs containing a planet, stellar activity, and noise, sampled using the
actual window function of 71 HARPS observations of the M dwarf K2-18 \citep{cloutier17b}.
The injected planetary
signal takes the form of a circular keplerian with $P=22$ days and $K=2$ \mps{.} The stellar
activity signal is derived from a physical spot model from \texttt{SOAP 2.0} \citep{dumusque14}
that computes time series of the photometric, RV, and line shape parameters resulting from
spots and/or plages on a rotating star. In this toy model I simulate a single equatorial spot
with 1\% fractional coverage of the visible stellar disk on a star with \prot{}$=30$ days.
White noise at the level of 1 \mps{} is also added to the RV time series.
The injected time series and the synthetic RVs are shown in the top panel of
Fig.~\ref{fig:RVsignals}. The injected activity signal is seen to have a peak-to-peak amplitude of
$\sim 8.5$ \mps{} and is dominated by the suppression of convective blueshift when the simulated
starspot is present on the visible hemisphere. The RV signal due to activity is equal to zero when
the lone starspot is not visible. The amplitude of the injected keplerian signal is seen to be
approximately a quarter that of the injected activity. \\

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/RVinjected.png}
  \includegraphics[width=\hsize]{figures/RVrecovered.png}
  \caption[Synthetic RV time series used to demonstrate the effectiveness of GP activity modelling.]
          {\emph{Top}: a synthetic RV time series with injected stellar activity from a \texttt{SOAP 2.0} physical
            model (\emph{red curve}), a keplerian planetary signal (\emph{blue curve}), and noise.
            The RVs (\emph{black markers}) are sampled with the real HARPS window
            function of K2-18. \emph{Bottom}: the recovered Gp activity model and keplerian model using the
            maximum a-posteriori model parameters from MCMC analysis. The recovered models closely resemble their
            injected counterparts (see Fig.~\ref{fig:RVcomp} for more details).}
  \label{fig:RVsignals}
\end{figure}

Next I impose a RV model that includes an activity component in the form of an untrained
quasi-periodic GP plus a single keplerian model of the planet that I treat as a transiting
planet such that its linear ephemeris (i.e. $P$ and $T_0$) are well-constrained by its transit
light curve. We note that untrained GPs can be dangerous as scenarios have been observed in which
an untrained GP model of RVs absorbs some planetary signal and can thus result in misestimated
planetary parameters \citep{ribas18}.
I proceed by deriving the joint posterior of the GP hyperparameters and keplerian
parameters to compute the `best-fit' GP and keplerian models that can then be compared to their
injected signal counterparts. The recovered models are shown in the bottom panel of
Fig.~\ref{fig:RVsignals}. Here the mean GP model is depicted along with its 68\% confidence
interval and appears to closely resemble the injected activity signal depsite being derived from
a semi-parametric model of a physically induced signal. \\

Fig.~\ref{fig:RVcomp} compares the recovered activity and planetary signals with the injected
signals. The mean GP model appears to have approximately the same period and phase as the injected activity
signal as it lies along the one-to-one line in Fig.~\ref{fig:RVcomp}. The residual RV rms between the
recovered and injected activity signals is 0.72 \mps{} compared to the injected RV measurement uncertainties
of 1 \mps{.} A notable exception to the inaccuracy of the GP activity model is in its failure to
capture the pile up of injected RVs at 0 \mps{} corresponding to when the single simulated starspot is
not visible. Although, the mean GP activity model at those epochs are often consistent within $1\sigma$ of
0 \mps{.} Similarly the recovered keplerian model is in phase and with the injected period owing to our
treatment of that signal as one whose ephemeris is well-constrained by some unseen hypothetical data.
The recovered semi-amplitude however is somewhat inaccurate at $K=1.83 \pm 0.55$ \mps{} which is underestimated
compared to the injected semi-amplitude of 2 \mps{.} However it is clearly consistent at the $1\sigma$ level.
This $\sim 10$\% underestimation in the value of $K$ causes the slight offset from unity in the slope
of the line in Fig.~\ref{fig:RVcomp} comparing the recovered and injected keplerian signals.

\begin{figure}
  \centering
  \includegraphics[width=\hsize]{figures/RVcomparison.png}
  \caption[Comparison of injected to recovered RV signals.]
          {\emph{Left panel}: comparison of the injected RV activity signal to the recovered GP activity model.
            The mean GP model appears to lie along the one-to-one line (\emph{black line}) with a residual rms
            of 0.72 \mps{.} \emph{Right panel}:
            comparison of the injected keplerian signal to the recovered keplerian model. }
  \label{fig:RVcomp}
\end{figure}


\subsection{Gaussian process regression packages}
Note that a number of packages exist for the efficient construction of GP prior distributions, function
sampling, and matrix algebra required to compute the data likelihoods (see Eq.~\ref{eq:lnlikeGP}).
Some such packages exist within the astronomy field as well as for implementation in broader contexts.
Examples of GP packages includes \texttt{scikit-learn} \citep{sklearn},
\texttt{gpytorch} \citep{gardner18,wang19},
\texttt{george} \citep{ambikasaran14,foremanmackey15b}, and
\texttt{celerite} \citep{foremanmackey17}.


\section{Point-form Thesis: Stellar Activity Modelling in Radial Velocity
  Time Series}
\begin{itemize}
\renewcommand\labelitemi{--}
\item~\ref{sect:methods} \textbf{An Overview of Techniques for Stellar Activity
  Mitigation}: a multitude of techniques for the mitigation of stellar activity in RV time series exist
  but many of them suffer from incompleteness and/or inaccuracy.
\item~\ref{sect:gp} \textbf{Gaussian Process Regression for Semi-Parametric
  Activity Modelling}: Gaussian process regression offers an alternative method to model
  stochastic activity signals within a semi-parametric Bayesian formalism that ensures consistency
  with modelled planetary signals.
\end{itemize}
